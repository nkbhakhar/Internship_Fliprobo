{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.A python program to scrape data for “Data Analyst” Job position in\n",
    "# Bangalore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=input('Enter the skill \\n') #taking input from the user \n",
    "location=input('Enter the location \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_skill=driver.find_element_by_xpath(\"//*[@id='qsb-keyword-sugg']\") #job search by skill\n",
    "job_search_skill.send_keys(skill) #entering key word \n",
    "job_search_location=driver.find_element_by_xpath('//*[@id=\"qsb-location-sugg\"]') #job search by location\n",
    "job_search_location.send_keys(location) #entering key word \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section/div/form/div[3]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job-title, job-location, ,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]    #empty list for storing data\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "for i in range(0,1):\n",
    "    for j in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "        job_title.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]'):\n",
    "        job_location.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company_name.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]'):\n",
    "        experience_required.append(m.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_DataAnalyst=pd.DataFrame({})\n",
    "For_DataAnalyst['Title']=job_title[0:10]   \n",
    "\n",
    "\n",
    "For_DataAnalyst['Location']=job_location[0:10]\n",
    "For_DataAnalyst['Company_Name']=company_name[0:10]\n",
    "For_DataAnalyst['Experience']=experience_required[0:10]\n",
    "s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "For_DataAnalyst.set_index([s])\n",
    "For_DataAnalyst.set_index([s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "DataAnalyst = For_DataAnalyst.to_csv('For_DataAnalyst', index=False)\n",
    "print('\\nCSV String:\\n',DataAnalyst )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.A python program to scrape data for “Data Analyst” Job position in\n",
    "# Bangalore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=input('Enter the skill \\n') #taking input from the user \n",
    "location=input('Enter the location \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_skill=driver.find_element_by_xpath(\"//*[@id='qsb-keyword-sugg']\") #job search by skill\n",
    "job_search_skill.send_keys(skill) #entering key word \n",
    "job_search_location=driver.find_element_by_xpath('//*[@id=\"qsb-location-sugg\"]') #job search by location\n",
    "job_search_location.send_keys(location) #entering key word \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section/div/form/div[3]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job-title, job-location, ,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in driver.find_elements_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div/a'):\n",
    "        title.append(j.get_attribute(\"href\"))\n",
    "        \n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=title[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_title=[]    #empty list for storing data\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "Job_Dec=[]\n",
    "\n",
    "for i in article:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    for j in driver.find_elements_by_xpath('//*[@id=\"root\"]/main/div[2]/div[2]/section[1]/div[1]/div[1]/header/h1'):\n",
    "        job_title.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//*[@id=\"root\"]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[3]'):\n",
    "        job_location.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//*[@id=\"root\"]/main/div[2]/div[2]/section[1]/div[1]/div[1]/div'):\n",
    "        company_name.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath('//*[@id=\"root\"]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[1]'):\n",
    "        experience_required.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath('//*[@id=\"root\"]/main/div[2]/div[2]/section[2]/div[1]'):\n",
    "        Job_Dec.append(n.text)    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_DataAnalyst=pd.DataFrame({})\n",
    "For_DataAnalyst['Title']=job_title[0:10]   \n",
    "\n",
    "\n",
    "For_DataAnalyst['Location']=job_location[0:10]\n",
    "For_DataAnalyst['Company_Name']=company_name[0:10]\n",
    "For_DataAnalyst['Experience']=experience_required[0:10]\n",
    "For_DataAnalyst['Discription']=Job_Dec[0:10]\n",
    "s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "For_DataAnalyst.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "DataAnalyst = For_DataAnalyst.to_csv('For_DataAnalyst', index=False)\n",
    "print('\\nCSV String:\\n',DataAnalyst )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.to scrape data using the filters available on the webpage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=input('Enter the skill \\n') #taking input from the user \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_skill=driver.find_element_by_xpath(\"//*[@id='qsb-keyword-sugg']\") #job search by skill\n",
    "job_search_skill.send_keys(skill) #entering key word \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section/div/form/div[3]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job-title, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_checkbox=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Location_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary_checkbox=driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary_checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job-title, job-location, company_name,\n",
    "#experience_required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_title=[]    #empty list for storing data\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[] \n",
    "for j in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "    job_title.append(j.text)\n",
    "for k in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]'):\n",
    "    job_location.append(k.text)\n",
    "for l in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "    company_name.append(l.text)\n",
    "for m in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]'):\n",
    "    experience_required.append(m.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_S=pd.DataFrame({})\n",
    "D_S['Title']=job_title[0:10]   \n",
    "\n",
    "\n",
    "D_S['Location']=job_location[0:10]\n",
    "D_S['Company_Name']=company_name[0:10]\n",
    "D_S['Experience']=experience_required[0:10]\n",
    "s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "D_S.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "DataScientist = D_S.to_csv('D_S', index=False)\n",
    "print('\\nCSV String:\\n',DataScientist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Python program to scrape data for first 10 job results for Data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "#in “location” field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=input('Enter the skill \\n') #taking input from the user \n",
    "location=input('Enter the location \\n')\n",
    "mail=input('Enter ur mail \\n')\n",
    "password=input('Enter ur  password \\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.glassdoor.co.in/index.htm') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signin_btn=driver.find_element_by_xpath('//button[@class=\"d-flex align-items-center justify-content-center order-1 order-md-2 mr-auto mr-md-0 p-0 LockedHomeHeaderStyles__signInButton\"]')\n",
    "signin_btn.click() #click sign in btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email=driver.find_element_by_xpath('//*[@id=\"userEmail\"]')\n",
    "email.send_keys(mail) #input email address for login\n",
    "user_password=driver.find_element_by_xpath('//input[@id=\"userPassword\"]')\n",
    "user_password.send_keys(password)  #input password for login\n",
    "sign_btn=driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]')\n",
    "sign_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_skill=driver.find_element_by_xpath('//input[@id=\"sc.keyword\"]') #job search by skill\n",
    "job_search_skill.send_keys(skill) #entering key word \n",
    "job_search_location=driver.find_element_by_xpath('//*[@id=\"sc.location\"]') #job search by location\n",
    "job_search_location.send_keys(location) #entering key word \n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]    #empty list for storing data\n",
    "days=[]\n",
    "company_name=[]\n",
    "\n",
    "for i in range(0,1):\n",
    "    for j in driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]'):\n",
    "        rating.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]'):\n",
    "        days.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]'):\n",
    "        company_name.append(l.text)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Datascientist=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Datascientist['Company_Name']=company_name[0:10]\n",
    "For_Datascientist['Days_job_posted']=days[0:10] \n",
    "For_Datascientist['Rating']=rating[0:10]\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) #seting index\n",
    "For_Datascientist.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill=input('Enter the skill \\n') #taking input from the user \n",
    "location=input('Enter the location \\n')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search_skill=driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]') #job search by skill\n",
    "job_search_skill.send_keys(skill) #entering key word \n",
    "job_search_location=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]') #job search by location\n",
    "job_search_location.send_keys(location) #entering key word \n",
    "time.sleep(3)\n",
    "search_btn=driver.find_element_by_xpath('//button[@id=\"HeroSearchButton\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape the min salary, max salary, company \n",
    "#name, Average salary and rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list for storing data\n",
    "Max_sal=[]\n",
    "Min_sal=[]\n",
    "av_sal=[]\n",
    "company_name=[]\n",
    "for i in range(0,1):\n",
    "    for k in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]'):\n",
    "        av_sal.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//p[@class=\"m-0 \"]'):\n",
    "        company_name.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[2]'):\n",
    "        Max_sal.append(m.text)\n",
    "   \n",
    "    for k in driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[1]'):\n",
    "        Min_sal.append(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Datascientist=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Datascientist['Company_Name']=company_name[0:10]\n",
    "For_Datascientist['Min_sal']=Min_sal[0:10] \n",
    "For_Datascientist['Max_sal']=Max_sal[0:10] \n",
    "For_Datascientist['av_sal']=av_sal[0:10]\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) #seting index\n",
    "For_Datascientist.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scrape data of first 100 sunglasses listings on flipkart.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item=input('Enter the item \\n') #taking input from the user \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item_search=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]') #search by item\n",
    "Item_search.send_keys(Item) #entering key word \n",
    "close_btn=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') #close login box\n",
    "close_btn.click()\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]    #empty list for storing data\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        Brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):\n",
    "        Product_Description.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        Price.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        Discount.append(m.text)\n",
    "    next_btn=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]/span[contains(text(), \"Next\")]')\n",
    "    next_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Item=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Item['Brand_Name']=Brand[0:100]\n",
    "For_Item['Description']=Product_Description[0:100] \n",
    "For_Item['Price']=Price[0:100]\n",
    "For_Item['Discount_%']=Discount[0:100]\n",
    "index=[]\n",
    "for i in range(0,100):\n",
    "    index.append(i+1)\n",
    "    \n",
    "s = pd.Series(index) #seting index\n",
    "For_Item.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. : Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Review=driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "All_Review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]    #empty list for storing data\n",
    "Summary=[]\n",
    "Full_Review=[]\n",
    "for i in range(0,11):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        Rating.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "        Summary.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):\n",
    "        Full_Review.append(l.text)\n",
    "    next_btn=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]/span[contains(text(), \"Next\")]')\n",
    "    next_btn.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Review=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Review['Rating']=Rating[0:100]\n",
    "For_Review['Summary']=Summary[0:100] \n",
    "For_Review['Full_Review']=Full_Review[0:100]\n",
    "index=[]\n",
    "for i in range(0,100):\n",
    "    index.append(i+1)\n",
    "    \n",
    "s = pd.Series(index) #seting index\n",
    "For_Review.set_index([s])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item=input('Enter the item \\n') #taking input from the user \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item_search=driver.find_element_by_xpath('//input[@class=\"_3704LK\"]') #search by item\n",
    "Item_search.send_keys(Item) #entering key word \n",
    "close_btn=driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]') #close login box\n",
    "close_btn.click()\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]    #empty list for storing data\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]\n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        Brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\" ]'):\n",
    "        Product_Description.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        Price.append(l.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        Discount.append(m.text)\n",
    "    next_btn=driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]/span[contains(text(), \"Next\")]')\n",
    "    next_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Product_Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Item=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Item['Brand_Name']=Brand[0:100]\n",
    "For_Item['Description']=Product_Description[0:100] \n",
    "For_Item['Price']=Price[0:100]\n",
    "For_Item['Discount_%']=Discount[0:100]\n",
    "index=[]\n",
    "for i in range(0,100):\n",
    "    index.append(i+1)\n",
    "    \n",
    "s = pd.Series(index) #seting index\n",
    "For_Item.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_filter=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div') #filter by price\n",
    "Price_filter.click() #clicking checkbox \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colour_filter=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div') #filter by colour\n",
    "Colour_filter.click() #clicking checkbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]    #empty list for storing data\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "for i in range(0,2):\n",
    "    for j in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "        Brand.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "        Product_Description.append(k.text)\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"product-price\"]' or '//span[@class=\"product-discountedPrice\"]'):\n",
    "        Price.append(l.text)\n",
    "    next_btn=driver.find_element_by_xpath('//a[contains(text(), \"Next\")]')\n",
    "    next_btn.click()\n",
    "    time.sleep(3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Product_Description)\n",
    "len(Brand)\n",
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Item=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Item['Brand_Name']=Brand[0:100]\n",
    "For_Item['Description']=Product_Description[0:100] \n",
    "For_Item['Price']=Price[0:100]\n",
    "index=[]\n",
    "for i in range(0,100):\n",
    "    index.append(i+1)\n",
    "    \n",
    "s = pd.Series(index) #seting index\n",
    "For_Item.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import all required liberary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\Dark box\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/') #site address to be scrapeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item_search=driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]') #search by item\n",
    "Item_search.send_keys('Laptop') #entering key word \n",
    "\n",
    "search_btn=driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cpu_filter1=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i') #filter by cpu\n",
    "Cpu_filter1.click() #clicking checkbox \n",
    "\n",
    "# as we cant use both filter simentensoly\n",
    "\n",
    "#Cpu_filter2=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div/label/i') #filter by cpu\n",
    "#Cpu_filter2.click() #clicking checkbox \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]    #empty list for storing data\n",
    "Rating=[]\n",
    "Price=[]\n",
    "for i in range(0,1):\n",
    "    for j in driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]'):\n",
    "        Title.append(j.text)\n",
    "    for n in driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]'):\n",
    "            Rating.append(n.text)\n",
    "   \n",
    "        \n",
    "    for l in driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]'):\n",
    "        Price.append(l.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For_Item=pd.DataFrame({}) #creating data frame\n",
    "\n",
    "For_Item['Name']=Title[0:10]\n",
    "For_Item['Rating']=Rating[0:10] \n",
    "For_Item['Price']=Price[0:10]\n",
    "index=[]\n",
    "for i in range(0,10):\n",
    "    index.append(i+1)\n",
    "    \n",
    "s = pd.Series(index) #seting index\n",
    "For_Item.set_index([s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "Datascientist = For_Datascientist.to_csv('For_Data_Scientest', index=False)\n",
    "print('\\nCSV String:\\n',Datascientist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
